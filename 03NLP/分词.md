# 理论
机器学习：HMM
深度学习：LSTM+CRF, BERT+CRF

CRF模型

维特比算法


# Jieba
jieba没有实现CRF, CRF比HMM好
提供了深度学习

## 默认参数
返回generator
``` python
def cut(self, sentence, cut_all=False, HMM=True, use_paddle=False)
```
返回list
```python
jieba.lcut()
```

调整词频
```python
jieba.suggest_freq('占比', tune=False) # tune = False, 打印词频，不调整词频
jieba.suggest_freq(('中', '将'), True) #修改词频 强制“中将” 分开
jieba.suggest_freq('占比', True) #强制让“占比”作为一次词
```

## 词性标注

```python
import jieba.posseg
```


## 并行分词

```python
jieba.enable_parallel() #只能在Linux
```

# HanLP
用BERT分词
提供CRF

- BasicToknerizer: 机器切分，维特比算法
- SpeedToknerizer: 词典，速度快，效果差
- IndexToknerizer: 搜索引擎分词器，类似于jie.cut_for_search
- CRFLexicalAnalyzer: CRF分词，同时返回分词，词性和命名实体