# 理论

基于矩阵分解的主题模型(矩阵分解)，基于神经网络的word2vec
## one-hot





## NNLM

National Network of Libraries of Medicine
前向滑动窗口，非两端

## word2vec

word2vec优化了NNLM, 去除了隐层
- CBOW:  两边预测中间
- Skip-Gram:  中间预测2端，能够覆盖的词更多

CBOW:  通过上下文词预测中心词
Skip-Gram: 通过中心词预测上下文词

优化技术：
Hierarchical Softmax：为了解决输出层的计算量，使用Hierarchical Softmax, 层次化的哈夫曼树
负采样：

缺点：不能处理近义词，比如苹果和苹果手机

# GloVe
优化word2vec只能在固定窗口分析


word2vec是静态
bert:  动态词向量，处理近意词


## n-gram
用统计学，概率估计来评估单词的概率




